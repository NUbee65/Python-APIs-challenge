{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WeatherPy\n",
    "----\n",
    "\n",
    "#### Note\n",
    "* Instructions have been included for each segment. You do not have to follow them exactly, but they are included to help you think through the steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Dependencies and Setup\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import time\n",
    "import calendar\n",
    "import math\n",
    "from datetime import date\n",
    "from scipy.stats import linregress\n",
    "\n",
    "# Import API keys\n",
    "from api_keys import weather_api_key\n",
    "from api_keys import g_key\n",
    "\n",
    "# Incorporated citipy to determine city based on latitude and longitude\n",
    "from citipy import citipy\n",
    "\n",
    "# Output File (CSV)\n",
    "output_data_file = \"../output_data/cities.csv\"\n",
    "\n",
    "# Range of latitudes and longitudes\n",
    "lat_range = (-90, 90)\n",
    "lng_range = (-180, 180)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Cities List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number randomly generated list of cities = 1147\n",
      "The number randomly generated list of city names = 1147\n",
      "The number randomly generated list of countries = 1147\n",
      "The number randomly generated list of latitude coordinates = 1147\n",
      "The number randomly generated list of longitude coordinates = 1147\n",
      "\n",
      "The number randomly generated list of unique countries = 154\n"
     ]
    }
   ],
   "source": [
    "# List for holding lat_lngs and cities\n",
    "lat_lngs = []\n",
    "success_lats = []\n",
    "success_lngs = []\n",
    "cities = []\n",
    "city_names = []\n",
    "countries = []\n",
    "city_country = []\n",
    "\n",
    "# Create a set of random lat and lng combinations\n",
    "lats = np.random.uniform(lat_range[0], lat_range[1], size=3500)\n",
    "lngs = np.random.uniform(lng_range[0], lng_range[1], size=3500)\n",
    "lat_lngs = zip(lats, lngs)\n",
    "\n",
    "# Identify nearest city for each lat, lng combination\n",
    "for lat_lng in lat_lngs:\n",
    "    city = citipy.nearest_city(lat_lng[0], lat_lng[1]) #.city_name\n",
    "    \n",
    "    # If the city is unique, then add it to the cities list\n",
    "    if city not in cities:\n",
    "        cities.append(city)\n",
    "        city_names.append(city.city_name)\n",
    "        countries.append(city.country_code)\n",
    "        success_lats.append(lat_lng[0])\n",
    "        success_lngs.append(lat_lng[1])\n",
    "\n",
    "# Print the city count to confirm sufficient count\n",
    "print(f\"The number randomly generated list of cities = {len(cities)}\")\n",
    "print(f\"The number randomly generated list of city names = {len(city_names)}\")\n",
    "print(f\"The number randomly generated list of countries = {len(countries)}\")\n",
    "print(f\"The number randomly generated list of latitude coordinates = {len(success_lats)}\")\n",
    "print(f\"The number randomly generated list of longitude coordinates = {len(success_lngs)}\")\n",
    "# print(f\"The number randomly generated list of city-country names = {len(city_country)}\")\n",
    "print()\n",
    "print(f\"The number randomly generated list of unique countries = {len(list(set(countries)))}\")\n",
    "\n",
    "# print(success_lats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City-Country</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Search Lats</th>\n",
       "      <th>Search Lngs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rikitea, pf</td>\n",
       "      <td>rikitea</td>\n",
       "      <td>pf</td>\n",
       "      <td>-48.841207</td>\n",
       "      <td>-129.272584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>taolanaro, mg</td>\n",
       "      <td>taolanaro</td>\n",
       "      <td>mg</td>\n",
       "      <td>-66.111554</td>\n",
       "      <td>68.316640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bredasdorp, za</td>\n",
       "      <td>bredasdorp</td>\n",
       "      <td>za</td>\n",
       "      <td>-87.130722</td>\n",
       "      <td>21.477709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tuktoyaktuk, ca</td>\n",
       "      <td>tuktoyaktuk</td>\n",
       "      <td>ca</td>\n",
       "      <td>89.338145</td>\n",
       "      <td>-119.150144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>utinga, br</td>\n",
       "      <td>utinga</td>\n",
       "      <td>br</td>\n",
       "      <td>-11.136789</td>\n",
       "      <td>-42.962918</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      City-Country         City Country  Search Lats  Search Lngs\n",
       "0      rikitea, pf      rikitea      pf   -48.841207  -129.272584\n",
       "1    taolanaro, mg    taolanaro      mg   -66.111554    68.316640\n",
       "2   bredasdorp, za   bredasdorp      za   -87.130722    21.477709\n",
       "3  tuktoyaktuk, ca  tuktoyaktuk      ca    89.338145  -119.150144\n",
       "4       utinga, br       utinga      br   -11.136789   -42.962918"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities_data = {\"City\": city_names, \"Country\": countries, \"Search Lats\": success_lats, \"Search Lngs\": success_lngs}\n",
    "cities_df = pd.DataFrame(cities_data)\n",
    "cities_df[\"City-Country\"] = cities_df[[\"City\", \"Country\"]].apply(lambda x: ', '.join(x[x.notnull()]), axis = 1)\n",
    "cities_df = cities_df[[\"City-Country\", \"City\", \"Country\", \"Search Lats\", \"Search Lngs\"]]\n",
    "\n",
    "cities_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1147"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cities_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In the starter code example, 1,500 sets of randomly chosen latitude and longitude yielded 635 unique city names.  That means that 58% of randomly chosen latitude-longitude coordinates were duplicates and were rejected, if we read the documentation correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Since 2/3 of the surface area of the globe is water, there is a likelihood that 2/3 of the choices made by randomly selecting geocoordinates will be somewhere other than on land, which means that at least 2/3 of the cities selected by using random coordinates will be clustered on shorelines.  Bottom line, the real task is to randomly select geocoordinates only for the 1/3 of the planet surface that is land.\n",
    "\n",
    "### Our solution is to reject any cities that are greater than 60 miles from the randomly chosen geocoordinates.  This requires me to measure the distance from the randomly chosen geocoordinates to the nearest city selected.  I may need to play with the method further to eyeball the best maximum distance.  With a highly iterative method, I could perhaps get maximum approximate equal distribution between cities to minimize any clustering tendencies. But I'm going to settle for an eyeball check on top of a pretty decent methodology.\n",
    "\n",
    "### We note that this methodology might skew away from cities in more remote locations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rikitea, pf',\n",
       " 'taolanaro, mg',\n",
       " 'bredasdorp, za',\n",
       " 'tuktoyaktuk, ca',\n",
       " 'utinga, br',\n",
       " 'upernavik, gl',\n",
       " 'ushuaia, ar',\n",
       " 'verkhnevilyuysk, ru',\n",
       " 'lompoc, us',\n",
       " 'inderborskiy, kz',\n",
       " 'hobart, au',\n",
       " 'kinsale, ie',\n",
       " 'hamilton, bm',\n",
       " 'bengkulu, id',\n",
       " 'wodonga, au',\n",
       " 'port alfred, za',\n",
       " 'micomeseng, gq',\n",
       " 'puerto leguizamo, co',\n",
       " 'aksu, kz',\n",
       " 'albany, au',\n",
       " 'papara, pf',\n",
       " 'luwingu, zm',\n",
       " 'khatanga, ru',\n",
       " 'ngunguru, nz',\n",
       " 'raga, sd',\n",
       " 'yellowknife, ca',\n",
       " 'broome, au',\n",
       " 'sao felix do xingu, br',\n",
       " 'vaini, to',\n",
       " 'puerto ayora, ec',\n",
       " 'homer, us',\n",
       " 'avarua, ck',\n",
       " 'butaritari, ki',\n",
       " 'waipawa, nz',\n",
       " 'punta arenas, cl',\n",
       " 'kodiak, us',\n",
       " 'narsaq, gl',\n",
       " 'mataura, pf',\n",
       " 'mount gambier, au',\n",
       " 'richards bay, za',\n",
       " 'kapaa, us',\n",
       " 'khonuu, ru',\n",
       " 'castro, cl',\n",
       " 'marsabit, ke',\n",
       " 'dambulla, lk',\n",
       " 'busselton, au',\n",
       " 'chagda, ru',\n",
       " 'erzin, ru',\n",
       " 'chokurdakh, ru',\n",
       " 'bluff, nz',\n",
       " 'alofi, nu',\n",
       " 'dakar, sn',\n",
       " 'nicoya, cr',\n",
       " 'jamestown, sh',\n",
       " 'belushya guba, ru',\n",
       " 'hermanus, za',\n",
       " 'jumla, np',\n",
       " 'velyka oleksandrivka, ua',\n",
       " 'kavieng, pg',\n",
       " 'saskylakh, ru',\n",
       " 'praia da vitoria, pt',\n",
       " 'auki, sb',\n",
       " 'saint-joseph, re',\n",
       " 'quang ngai, vn',\n",
       " 'beringovskiy, ru',\n",
       " 'coihaique, cl',\n",
       " 'watrous, ca',\n",
       " 'akdepe, tm',\n",
       " 'svetlaya, ru',\n",
       " 'ulaangom, mn',\n",
       " 'guerrero negro, mx',\n",
       " 'gat, ly',\n",
       " 'provideniya, ru',\n",
       " 'madang, pg',\n",
       " 'cape town, za',\n",
       " 'kaitangata, nz',\n",
       " 'tumannyy, ru',\n",
       " 'tim, ru',\n",
       " 'ithaca, us',\n",
       " 'goderich, sl',\n",
       " 'krasnoye, ru',\n",
       " 'wladyslawowo, pl',\n",
       " 'constitucion, mx',\n",
       " 'mopti, ml',\n",
       " 'shwebo, mm',\n",
       " 'daru, pg',\n",
       " 'mount isa, au',\n",
       " 'temnikov, ru',\n",
       " 'fuxin, cn',\n",
       " 'longyearbyen, sj',\n",
       " 'san quintin, mx',\n",
       " 'hilo, us',\n",
       " 'norsup, vu',\n",
       " 'oktyabrskoye, ru',\n",
       " 'vicuna, cl',\n",
       " 'hohhot, cn',\n",
       " 'barentsburg, sj',\n",
       " 'atuona, pf',\n",
       " 'victoria, sc',\n",
       " 'wulanhaote, cn',\n",
       " 'mikuni, jp',\n",
       " 'praya, id',\n",
       " 'ostrovnoy, ru',\n",
       " 'karpathos, gr',\n",
       " 'savannah bight, hn',\n",
       " 'shirokiy, ru',\n",
       " 'kutum, sd',\n",
       " 'balimo, pg',\n",
       " 'deputatskiy, ru',\n",
       " 'ballina, au',\n",
       " 'belaya gora, ru',\n",
       " 'rio grande, br',\n",
       " 'aquiraz, br',\n",
       " 'vao, nc',\n",
       " 'yatou, cn',\n",
       " 'avera, pf',\n",
       " 'vitim, ru',\n",
       " 'sechura, pe',\n",
       " 'surt, ly',\n",
       " 'shingu, jp',\n",
       " 'barrow, us',\n",
       " 'yarensk, ru',\n",
       " 'whitehorse, ca',\n",
       " 'mar del plata, ar',\n",
       " 'slave lake, ca',\n",
       " 'port elizabeth, za',\n",
       " 'honiara, sb',\n",
       " 'turukhansk, ru',\n",
       " 'taburi, ph',\n",
       " 'manzil tamim, tn',\n",
       " 'yerbogachen, ru',\n",
       " 'husavik, is',\n",
       " 'norman wells, ca',\n",
       " 'qaanaaq, gl',\n",
       " 'mukhen, ru',\n",
       " 'oussouye, sn',\n",
       " 'aklavik, ca',\n",
       " 'dingle, ie',\n",
       " 'ribeira grande, pt',\n",
       " 'charters towers, au',\n",
       " 'kochi, in',\n",
       " 'thompson, ca',\n",
       " 'adrar, dz',\n",
       " 'kahului, us',\n",
       " 'san fernando, mx',\n",
       " 'cairns, au',\n",
       " 'hithadhoo, mv',\n",
       " 'york, gb',\n",
       " 'general roca, ar',\n",
       " 'illoqqortoormiut, gl',\n",
       " 'aksarayskiy, ru',\n",
       " 'san policarpo, ph',\n",
       " 'bella vista, pa',\n",
       " 'arona, es',\n",
       " 'qiongshan, cn',\n",
       " 'olafsvik, is',\n",
       " 'cabo san lucas, mx',\n",
       " 'tasiilaq, gl',\n",
       " 'kieta, pg',\n",
       " 'srednekolymsk, ru',\n",
       " 'oudtshoorn, za',\n",
       " 'ardakan, ir',\n",
       " 'sabancuy, mx',\n",
       " 'georgetown, sh',\n",
       " 'ponta do sol, cv',\n",
       " 'tiksi, ru',\n",
       " 'shibetsu, jp',\n",
       " 'beloha, mg',\n",
       " 'dobromir, ro',\n",
       " 'naze, jp',\n",
       " 'banda aceh, id',\n",
       " 'panaba, mx',\n",
       " 'banjar, id',\n",
       " 'port lincoln, au',\n",
       " 'arraial do cabo, br',\n",
       " 'georgiyevka, ru',\n",
       " 'faanui, pf',\n",
       " 'carnarvon, au',\n",
       " 'clyde river, ca',\n",
       " 'wakkanai, jp',\n",
       " 'chicama, pe',\n",
       " 'iquique, cl',\n",
       " 'paradwip, in',\n",
       " 'kousseri, cm',\n",
       " 'margate, za',\n",
       " 'hambantota, lk',\n",
       " 'canutama, br',\n",
       " 'saint george, bm',\n",
       " 'paamiut, gl',\n",
       " 'comodoro rivadavia, ar',\n",
       " 'airai, pw',\n",
       " 'port blair, in',\n",
       " 'iskateley, ru',\n",
       " 'chuy, uy',\n",
       " 'nizhneyansk, ru',\n",
       " 'bethel, us',\n",
       " 'cidreira, br',\n",
       " 'acajutla, sv',\n",
       " 'schenectady, us',\n",
       " 'saleaula, ws',\n",
       " 'severo-yeniseyskiy, ru',\n",
       " 'mahebourg, mu',\n",
       " 'shymkent, kz',\n",
       " 'saldanha, za',\n",
       " 'east london, za',\n",
       " 'amderma, ru',\n",
       " 'tabuk, sa',\n",
       " 'port-gentil, ga',\n",
       " 'soe, id',\n",
       " 'carnarvon, za',\n",
       " 'tessalit, ml',\n",
       " 'bambous virieux, mu',\n",
       " 'lebu, cl',\n",
       " 'komsomolskiy, ru',\n",
       " 'cortez, us',\n",
       " 'marcona, pe',\n",
       " 'uige, ao',\n",
       " 'hermosillo, mx',\n",
       " 'isangel, vu',\n",
       " 'atar, mr',\n",
       " 'pokhara, np',\n",
       " 'ust-kut, ru',\n",
       " 'puerto baquerizo moreno, ec',\n",
       " 'katsuura, jp',\n",
       " 'opuwo, na',\n",
       " 'semnan, ir',\n",
       " 'fenoarivo, mg',\n",
       " 'lugovoy, ru',\n",
       " 'lodeynoye pole, ru',\n",
       " 'beaupre, ca',\n",
       " 'honningsvag, no',\n",
       " 'yulara, au',\n",
       " 'lima, pe',\n",
       " 'lata, sb',\n",
       " 'yanam, in',\n",
       " 'havelock, us',\n",
       " 'synya, ru',\n",
       " 'karkaralinsk, kz',\n",
       " 'sao filipe, cv',\n",
       " 'bubaque, gw',\n",
       " 'gazanjyk, tm',\n",
       " 'vaghodia, in',\n",
       " 'pascagoula, us',\n",
       " 'grindavik, is',\n",
       " 'tiznit, ma',\n",
       " 'sur, om',\n",
       " 'ancud, cl',\n",
       " 'nanyang, cn',\n",
       " 'mutare, zw',\n",
       " 'kruisfontein, za',\n",
       " 'nome, us',\n",
       " 'kodinsk, ru',\n",
       " 'esperance, au',\n",
       " 'odweyne, so',\n",
       " 'chulman, ru',\n",
       " 'nikolskoye, ru',\n",
       " 'chegdomyn, ru',\n",
       " 'kashi, cn',\n",
       " 'cayenne, gf',\n",
       " 'mairi, br',\n",
       " 'olean, us',\n",
       " 'itarema, br',\n",
       " 'talnakh, ru',\n",
       " 'fortuna, us',\n",
       " 'lavrentiya, ru',\n",
       " 'safaga, eg',\n",
       " 'namatanai, pg',\n",
       " 'vernon, ca',\n",
       " 'umzimvubu, za',\n",
       " 'kamenskoye, ru',\n",
       " 'iqaluit, ca',\n",
       " 'solwezi, zm',\n",
       " 'sompeta, in',\n",
       " 'marfino, ru',\n",
       " 'labuhan, id',\n",
       " 'ilulissat, gl',\n",
       " 'svetlogorsk, ru',\n",
       " 'sao gabriel da cachoeira, br',\n",
       " 'hobyo, so',\n",
       " 'tuatapere, nz',\n",
       " 'bereda, so',\n",
       " 'hamilton, us',\n",
       " 'sesheke, zm',\n",
       " 'torbay, ca',\n",
       " 'jalu, ly',\n",
       " 'lorengau, pg',\n",
       " 'wanning, cn',\n",
       " 'solovetskiy, ru',\n",
       " 'tigil, ru',\n",
       " 'luwuk, id',\n",
       " 'viedma, ar',\n",
       " 'sola, vu',\n",
       " 'amahai, id',\n",
       " 'borba, pt',\n",
       " 'lilongwe, mw',\n",
       " 'malesici, ba',\n",
       " 'riedlingen, de',\n",
       " 'raudeberg, no',\n",
       " 'champerico, gt',\n",
       " 'gornopravdinsk, ru',\n",
       " 'mandalgovi, mn',\n",
       " 'nuevo progreso, mx',\n",
       " 'namibe, ao',\n",
       " 'yumen, cn',\n",
       " 'mys shmidta, ru',\n",
       " 'karlstad, se',\n",
       " 'skagastrond, is',\n",
       " 'san patricio, mx',\n",
       " 'geraldton, ca',\n",
       " 'port hardy, ca',\n",
       " 'flinders, au',\n",
       " 'estelle, us',\n",
       " 'grand gaube, mu',\n",
       " 'bournemouth, gb',\n",
       " 'antagan, ph',\n",
       " 'sulangan, ph',\n",
       " 'altay, cn',\n",
       " 'shahapur, in',\n",
       " 'komatipoort, za',\n",
       " 'saint-dizier, fr',\n",
       " 'ormara, pk',\n",
       " 'oranjemund, na',\n",
       " 'vardo, no',\n",
       " 'kenda, in',\n",
       " 'yuncheng, cn',\n",
       " 'vagur, fo',\n",
       " 'mardin, tr',\n",
       " 'oriximina, br',\n",
       " 'abrau-dyurso, ru',\n",
       " 'bassila, bj',\n",
       " 'tecpan, mx',\n",
       " 'acapulco, mx',\n",
       " 'kushiro, jp',\n",
       " 'attawapiskat, ca',\n",
       " 'korla, cn',\n",
       " 'petropavlovsk-kamchatskiy, ru',\n",
       " 'grand river south east, mu',\n",
       " 'mamakan, ru',\n",
       " 'maldonado, uy',\n",
       " 'natal, br',\n",
       " 'ahipara, nz',\n",
       " 'berlevag, no',\n",
       " 'okhotsk, ru',\n",
       " 'lasa, cn',\n",
       " 'baghdad, iq',\n",
       " 'hay river, ca',\n",
       " 'severo-kurilsk, ru',\n",
       " 'kamaishi, jp',\n",
       " 'pangody, ru',\n",
       " 'raipur, in',\n",
       " 'luanda, ao',\n",
       " 'sitka, us',\n",
       " 'dujuma, so',\n",
       " 'bolton, ca',\n",
       " 'eatonton, us',\n",
       " 'samusu, ws',\n",
       " 'akyab, mm',\n",
       " 'keti bandar, pk',\n",
       " 'geraldton, au',\n",
       " 'vaitape, pf',\n",
       " 'tezu, in',\n",
       " 'mutis, co',\n",
       " 'mercedes, uy',\n",
       " 'bitung, id',\n",
       " 'saryshagan, kz',\n",
       " 'granja, br',\n",
       " 'te anau, nz',\n",
       " 'walvis bay, na',\n",
       " 'esna, eg',\n",
       " 'kismayo, so',\n",
       " 'van, tr',\n",
       " 'los llanos de aridane, es',\n",
       " 'the valley, ai',\n",
       " 'farafenni, gm',\n",
       " 'westport, ie',\n",
       " 'boende, cd',\n",
       " 'hasaki, jp',\n",
       " 'sungaipenuh, id',\n",
       " 'darhan, mn',\n",
       " 'shelburne, ca',\n",
       " 'pevek, ru',\n",
       " 'kimbe, pg',\n",
       " 'sulphur, us',\n",
       " 'emerald, au',\n",
       " 'vidim, ru',\n",
       " 'inirida, co',\n",
       " 'uray, ru',\n",
       " 'rudnyy, ru',\n",
       " 'tarauaca, br',\n",
       " 'seoul, kr',\n",
       " 'tahe, cn',\n",
       " 'sohagpur, in',\n",
       " 'nanortalik, gl',\n",
       " 'dzaoudzi, yt',\n",
       " 'rabo de peixe, pt',\n",
       " 'bouillante, gp',\n",
       " 'paracuru, br',\n",
       " 'salinopolis, br',\n",
       " 'haibowan, cn',\n",
       " 'abu samrah, qa',\n",
       " 'goundam, ml',\n",
       " 'saint-philippe, re',\n",
       " 'mananjary, mg',\n",
       " 'pemangkat, id',\n",
       " 'launceston, au',\n",
       " 'kribi, cm',\n",
       " 'petrokamenskoye, ru',\n",
       " 'kang, bw',\n",
       " 'new norfolk, au',\n",
       " 'san jose, gt',\n",
       " 'birao, cf',\n",
       " 'pontianak, id',\n",
       " 'horki, by',\n",
       " 'caravelas, br',\n",
       " 'zanjan, ir',\n",
       " 'usolye, ru',\n",
       " 'saint-augustin, ca',\n",
       " 'mersing, my',\n",
       " 'biltine, td',\n",
       " 'dunedin, nz',\n",
       " 'ust-kulom, ru',\n",
       " 'hvolsvollur, is',\n",
       " 'hihifo, to',\n",
       " 'huicheng, cn',\n",
       " 'nhulunbuy, au',\n",
       " 'pemba, mz',\n",
       " 'cururupu, br',\n",
       " 'boca do acre, br',\n",
       " 'key west, us',\n",
       " 'shimoda, jp',\n",
       " 'mabaruma, gy',\n",
       " 'aleksandrovsk-sakhalinskiy, ru',\n",
       " 'joshimath, in',\n",
       " 'valparaiso, cl',\n",
       " 'antalaha, mg',\n",
       " 'leh, in',\n",
       " 'meulaboh, id',\n",
       " 'ponta do sol, pt',\n",
       " 'tukrah, ly',\n",
       " 'north bend, us',\n",
       " 'moose factory, ca',\n",
       " 'barentu, er',\n",
       " 'khromtau, kz',\n",
       " 'saint-georges, gf',\n",
       " 'sorsk, ru',\n",
       " 'leningradskiy, ru',\n",
       " 'katobu, id',\n",
       " 'belyy yar, ru',\n",
       " 'harbin, cn',\n",
       " 'ateli, in',\n",
       " 'havre-saint-pierre, ca',\n",
       " 'mwinilunga, zm',\n",
       " 'turtas, ru',\n",
       " 'novonukutskiy, ru',\n",
       " 'puerto escondido, mx',\n",
       " 'superior, us',\n",
       " 'durusu, tr',\n",
       " 'tsienyane, bw',\n",
       " 'sovetskiy, tj',\n",
       " 'presidente medici, br',\n",
       " 'klyuchi, ru',\n",
       " 'bambanglipuro, id',\n",
       " 'ust-kuyga, ru',\n",
       " 'tarudant, ma',\n",
       " 'coahuayana, mx',\n",
       " 'muli, mv',\n",
       " 'dzhusaly, kz',\n",
       " 'hovd, mn',\n",
       " 'souillac, mu',\n",
       " 'karratha, au',\n",
       " 'lapua, fi',\n",
       " 'nohar, in',\n",
       " 'batagay-alyta, ru',\n",
       " 'murchison, nz',\n",
       " 'awjilah, ly',\n",
       " 'kathu, th',\n",
       " 'yar-sale, ru',\n",
       " 'sale, au',\n",
       " 'tadine, nc',\n",
       " 'strezhevoy, ru',\n",
       " 'sao joao da barra, br',\n",
       " 'pochutla, mx',\n",
       " 'minas, uy',\n",
       " 'kudahuvadhoo, mv',\n",
       " 'chernyshevsk, ru',\n",
       " 'jurilovca, ro',\n",
       " 'dolores, ar',\n",
       " 'baykit, ru',\n",
       " 'brae, gb',\n",
       " 'haines junction, ca',\n",
       " 'phan thiet, vn',\n",
       " 'ocos, gt',\n",
       " 'kavaratti, in',\n",
       " 'areado, br',\n",
       " 'pop, uz',\n",
       " 'shelton, us',\n",
       " 'vestmannaeyjar, is',\n",
       " 'alice springs, au',\n",
       " 'coquimbo, cl',\n",
       " 'rypefjord, no',\n",
       " 'alekseyevsk, ru',\n",
       " 'upington, za',\n",
       " 'bilma, ne',\n",
       " 'tual, id',\n",
       " 'palu, id',\n",
       " 'la baule-escoublac, fr',\n",
       " 'skvyra, ua',\n",
       " 'tautira, pf',\n",
       " 'borogontsy, ru',\n",
       " 'santa rosa, bo',\n",
       " 'santander, es',\n",
       " 'manzil salim, tn',\n",
       " 'marshall, us',\n",
       " 'khorinsk, ru',\n",
       " 'buchanan, lr',\n",
       " 'hami, cn',\n",
       " 'treinta y tres, uy',\n",
       " 'kuytun, cn',\n",
       " 'nyurba, ru',\n",
       " 'karaul, ru',\n",
       " 'shitanjing, cn',\n",
       " 'rawson, ar',\n",
       " 'borlange, se',\n",
       " 'kottayam, in',\n",
       " 'aksarka, ru',\n",
       " 'agadez, ne',\n",
       " 'artyk, ru',\n",
       " 'roald, no',\n",
       " 'paita, pe',\n",
       " 'bria, cf',\n",
       " 'camana, pe',\n",
       " 'nisporeni, md',\n",
       " 'taksimo, ru',\n",
       " 'englewood, us',\n",
       " 'bandarbeyla, so',\n",
       " 'quelimane, mz',\n",
       " 'matameye, ne',\n",
       " 'dinar, tr',\n",
       " 'saint anthony, ca',\n",
       " 'lahaina, us',\n",
       " 'erenhot, cn',\n",
       " 'morondava, mg',\n",
       " 'chernyshevskiy, ru',\n",
       " 'warqla, dz',\n",
       " 'sabang, id',\n",
       " 'leningradskiy, tj',\n",
       " 'chornukhy, ua',\n",
       " 'picos, br',\n",
       " 'kroya, id',\n",
       " 'gorno-chuyskiy, ru',\n",
       " 'maceio, br',\n",
       " 'tokur, ru',\n",
       " 'dikson, ru',\n",
       " 'bonavista, ca',\n",
       " 'boleslawiec, pl',\n",
       " 'wasilla, us',\n",
       " 'smolyaninovo, ru',\n",
       " 'ukiah, us',\n",
       " 'half moon bay, us',\n",
       " 'greenwood, us',\n",
       " 'ngorongoro, tz',\n",
       " 'cherskiy, ru',\n",
       " 'muzquiz, mx',\n",
       " 'bowen, au',\n",
       " 'guiyang, cn',\n",
       " 'urdzhar, kz',\n",
       " 'palabuhanratu, id',\n",
       " 'tanout, ne',\n",
       " 'chimore, bo',\n",
       " 'roebourne, au',\n",
       " 'santa maria del oro, mx',\n",
       " 'santiago del estero, ar',\n",
       " 'manacor, es',\n",
       " 'tasbuget, kz',\n",
       " 'coihueco, cl',\n",
       " 'omboue, ga',\n",
       " 'along, in',\n",
       " 'saint-leu, re',\n",
       " 'smithers, ca',\n",
       " 'yamada, jp',\n",
       " 'dalvik, is',\n",
       " 'rincon, an',\n",
       " 'vrsac, rs',\n",
       " 'thessalon, ca',\n",
       " 'cedral, mx',\n",
       " 'ternate, id',\n",
       " 'sibiti, cg',\n",
       " 'sentyabrskiy, ru',\n",
       " 'susanville, us',\n",
       " 'kununurra, au',\n",
       " 'bathsheba, bb',\n",
       " 'yirol, sd',\n",
       " 'falealupo, ws',\n",
       " 'dawei, mm',\n",
       " 'kilmez, ru',\n",
       " 'marathopolis, gr',\n",
       " 'padang, id',\n",
       " 'terney, ru',\n",
       " 'elizabeth city, us',\n",
       " 'college, us',\n",
       " 'plettenberg bay, za',\n",
       " 'vaitupu, wf',\n",
       " 'lagoa, pt',\n",
       " 'tsihombe, mg',\n",
       " 'nevesinje, ba',\n",
       " 'qovlar, az',\n",
       " 'bad salzungen, de',\n",
       " 'hudson bay, ca',\n",
       " 'ayna, pe',\n",
       " 'bari, it',\n",
       " 'lufilufi, ws',\n",
       " 'benguela, ao',\n",
       " 'twentynine palms, us',\n",
       " 'kolpny, ru',\n",
       " 'guider, cm',\n",
       " 'otane, nz',\n",
       " 'ozgon, kg',\n",
       " 'sun city west, us',\n",
       " 'acaponeta, mx',\n",
       " 'teocaltiche, mx',\n",
       " 'hualmay, pe',\n",
       " 'tura, ru',\n",
       " 'ewa beach, us',\n",
       " 'houston, ca',\n",
       " 'kasongo-lunda, cd',\n",
       " 'bolungarvik, is',\n",
       " 'turinsk, ru',\n",
       " 'zemetchino, ru',\n",
       " 'spirovo, ru',\n",
       " 'virginia beach, us',\n",
       " 'gambela, et',\n",
       " 'dukat, ru',\n",
       " 'ndola, zm',\n",
       " 'turbe, ba',\n",
       " 'tefe, br',\n",
       " 'wynyard, ca',\n",
       " 'chabahar, ir',\n",
       " 'ampanihy, mg',\n",
       " 'tommot, ru',\n",
       " 'riverton, us',\n",
       " 'sorvag, fo',\n",
       " 'quesnel, ca',\n",
       " 'narrabri, au',\n",
       " 'mezen, ru',\n",
       " 'zhuhai, cn',\n",
       " 'terrace bay, ca',\n",
       " 'bulgan, mn',\n",
       " 'tarakan, id',\n",
       " 'mahon, es',\n",
       " 'zhigansk, ru',\n",
       " 'tatawin, tn',\n",
       " 'zambezi, zm',\n",
       " 'aras, no',\n",
       " 'longonjo, ao',\n",
       " 'rulenge, tz',\n",
       " 'angoche, mz',\n",
       " 'boden, se',\n",
       " 'floriano, br',\n",
       " 'cap malheureux, mu',\n",
       " 'massakory, td',\n",
       " 'buala, sb',\n",
       " 'santa fe, us',\n",
       " 'tapel, ph',\n",
       " 'tara, ru',\n",
       " 'camacha, pt',\n",
       " 'satitoa, ws',\n",
       " 'warrington, us',\n",
       " 'ayodhya, in',\n",
       " 'novyy urengoy, ru',\n",
       " 'tabiauea, ki',\n",
       " 'baruun-urt, mn',\n",
       " 'yangambi, cd',\n",
       " 'ranong, th',\n",
       " 'asau, tv',\n",
       " 'dunmore town, bs',\n",
       " 'moerai, pf',\n",
       " 'lolua, tv',\n",
       " 'galiwinku, au',\n",
       " 'thinadhoo, mv',\n",
       " 'wajid, so',\n",
       " 'mackenzie, ca',\n",
       " 'karauzyak, uz',\n",
       " 'kamenka, ru',\n",
       " 'chitungwiza, zw',\n",
       " 'san cristobal, ec',\n",
       " 'grand falls, ca',\n",
       " 'wangqing, cn',\n",
       " 'kalas, in',\n",
       " 'springdale, ca',\n",
       " 'nara, ml',\n",
       " 'vorobyevka, ru',\n",
       " 'sanson, nz',\n",
       " 'galle, lk',\n",
       " 'montespertoli, it',\n",
       " 'forestville, ca',\n",
       " 'wattegama, lk',\n",
       " 'youhao, cn',\n",
       " 'callaway, us',\n",
       " 'hurricane, us',\n",
       " 'marrakesh, ma',\n",
       " 'beira, mz',\n",
       " 'klaksvik, fo',\n",
       " 'nouakchott, mr',\n",
       " 'ijaki, ki',\n",
       " 'cajati, br',\n",
       " 'high level, ca',\n",
       " 'labutta, mm',\n",
       " 'la ronge, ca',\n",
       " 'sioux lookout, ca',\n",
       " 'talaya, ru',\n",
       " 'teneguiban, ph',\n",
       " 'sargatskoye, ru',\n",
       " 'mehamn, no',\n",
       " 'ola, ru',\n",
       " 'soubre, ci',\n",
       " 'nago, jp',\n",
       " 'richmond, za',\n",
       " 'denpasar, id',\n",
       " 'amapa, br',\n",
       " 'hervey bay, au',\n",
       " 'shubarshi, kz',\n",
       " 'rawannawi, ki',\n",
       " 'one hundred mile house, ca',\n",
       " 'marsh harbour, bs',\n",
       " 'rocha, uy',\n",
       " 'celestun, mx',\n",
       " 'kovur, in',\n",
       " 'dauriya, ru',\n",
       " 'kota kinabalu, my',\n",
       " 'turangi, nz',\n",
       " 'yabelo, et',\n",
       " 'aswan, eg',\n",
       " 'bossangoa, cf',\n",
       " 'ambagarh chauki, in',\n",
       " 'nador, ma',\n",
       " 'beian, cn',\n",
       " 'bairiki, ki',\n",
       " 'katubao, ph',\n",
       " 'xingyi, cn',\n",
       " 'pisco, pe',\n",
       " 'pleasanton, us',\n",
       " 'bosaso, so',\n",
       " 'puerto del rosario, es',\n",
       " 'nemuro, jp',\n",
       " 'sangar, ru',\n",
       " 'codrington, ag',\n",
       " 'guaruja, br',\n",
       " 'sonari, in',\n",
       " 'peace river, ca',\n",
       " 'sokoto, ng',\n",
       " 'pangnirtung, ca',\n",
       " 'colorines, mx',\n",
       " 'larap, ph',\n",
       " 'blacksburg, us',\n",
       " 'mirpur sakro, pk',\n",
       " 'segamat, my',\n",
       " 'matagami, ca',\n",
       " 'sao sebastiao, br',\n",
       " 'shkotovo-22, ru',\n",
       " 'ninh binh, vn',\n",
       " 'abashiri, jp',\n",
       " 'nambucca heads, au',\n",
       " 'shangrao, cn',\n",
       " 'yavaros, mx',\n",
       " 'melfi, td',\n",
       " 'la spezia, it',\n",
       " 'vila franca do campo, pt',\n",
       " 'catamarca, ar',\n",
       " 'inhambane, mz',\n",
       " 'casper, us',\n",
       " 'laguna, br',\n",
       " 'maiduguri, ng',\n",
       " 'san jeronimo, mx',\n",
       " 'mbini, gq',\n",
       " 'marawi, sd',\n",
       " 'segou, ml',\n",
       " 'fairbanks, us',\n",
       " 'klyuchi, ru',\n",
       " 'ibitinga, br',\n",
       " 'ishigaki, jp',\n",
       " 'hofn, is',\n",
       " 'ucluelet, ca',\n",
       " 'salalah, om',\n",
       " 'jaciara, br',\n",
       " 'kaeo, nz',\n",
       " 'liku, wf',\n",
       " 'eilenburg, de',\n",
       " 'white rock, ca',\n",
       " 'basoko, cd',\n",
       " 'macheng, cn',\n",
       " 'ati, td',\n",
       " 'camopi, gf',\n",
       " 'itacare, br',\n",
       " 'biak, id',\n",
       " 'sinnamary, gf',\n",
       " 'ponta delgada, pt',\n",
       " 'kavali, in',\n",
       " 'lodja, cd',\n",
       " 'diapaga, bf',\n",
       " 'chirongui, yt',\n",
       " 'mocuba, mz',\n",
       " 'dickinson, us',\n",
       " 'simao, cn',\n",
       " 'xuddur, so',\n",
       " 'mayo, ca',\n",
       " 'nauta, pe',\n",
       " 'abapo, bo',\n",
       " 'mandera, ke',\n",
       " 'ewo, cg',\n",
       " 'francisco beltrao, br',\n",
       " 'raton, us',\n",
       " 'diamantino, br',\n",
       " 'teya, ru',\n",
       " 'pacific grove, us',\n",
       " 'soyo, ao',\n",
       " 'nouadhibou, mr',\n",
       " 'usinsk, ru',\n",
       " 'broken hill, au',\n",
       " 'degirmen, tr',\n",
       " 'mao, td',\n",
       " 'pudozh, ru',\n",
       " 'tenango, mx',\n",
       " 'chimbote, pe',\n",
       " 'felipe carrillo puerto, mx',\n",
       " 'victor harbor, au',\n",
       " 'ye, mm',\n",
       " 'toliary, mg',\n",
       " 'dubrovnik, hr',\n",
       " 'bac can, vn',\n",
       " 'sosnovo-ozerskoye, ru',\n",
       " 'magadan, ru',\n",
       " 'porto novo, cv',\n",
       " 'jiwani, pk',\n",
       " 'rantepao, id',\n",
       " 'astoria, us',\n",
       " 'lerma, mx',\n",
       " 'labytnangi, ru',\n",
       " 'port macquarie, au',\n",
       " 'popondetta, pg',\n",
       " 'sorgun, tr',\n",
       " 'sao gabriel, br',\n",
       " 'anadyr, ru',\n",
       " 'maniwaki, ca',\n",
       " 'kenai, us',\n",
       " 'tres arroyos, ar',\n",
       " 'mitsamiouli, km',\n",
       " 'phan rang, vn',\n",
       " 'krasnaya polyana, ru',\n",
       " 'fort saint james, ca',\n",
       " 'cockburn harbour, tc',\n",
       " 'lebyazhye, ru',\n",
       " 'byron bay, au',\n",
       " 'rustenburg, za',\n",
       " 'tarancon, es',\n",
       " 'barcelos, br',\n",
       " 'mana, gf',\n",
       " 'tallahassee, us',\n",
       " 'faya, td',\n",
       " 'agadir, ma',\n",
       " 'kushmurun, kz',\n",
       " 'baillif, gp',\n",
       " 'jiddah, sa',\n",
       " 'penzance, gb',\n",
       " 'katherine, au',\n",
       " 'roma, au',\n",
       " 'tapaua, br',\n",
       " 'alegrete, br',\n",
       " 'bongandanga, cd',\n",
       " 'carrizal, ve',\n",
       " 'smirnykh, ru',\n",
       " 'ningxiang, cn',\n",
       " 'luderitz, na',\n",
       " 'tondano, id',\n",
       " 'oga, jp',\n",
       " 'tocache, pe',\n",
       " 'luganville, vu',\n",
       " 'tamasopo, mx',\n",
       " 'orotina, cr',\n",
       " 'inta, ru',\n",
       " 'ipixuna, br',\n",
       " 'sedelnikovo, ru',\n",
       " 'kloulklubed, pw',\n",
       " 'matara, lk',\n",
       " 'morehead, pg',\n",
       " 'ixtapa, mx',\n",
       " 'pafos, cy',\n",
       " 'fare, pf',\n",
       " 'yuzhno-kurilsk, ru',\n",
       " 'dongsheng, cn',\n",
       " 'samarai, pg',\n",
       " 'barkly west, za',\n",
       " 'salta, ar',\n",
       " 'areosa, pt',\n",
       " 'dicabisagan, ph',\n",
       " 'sokol, ru',\n",
       " 'pitimbu, br',\n",
       " 'beyneu, kz',\n",
       " 'tamworth, au',\n",
       " 'lyaskelya, ru',\n",
       " 'mkushi, zm',\n",
       " 'kasane, bw',\n",
       " 'el dorado, co',\n",
       " 'sakakah, sa',\n",
       " 'trinidad, us',\n",
       " 'chumikan, ru',\n",
       " 'olecko, pl',\n",
       " 'filingue, ne',\n",
       " 'utmanzai, pk',\n",
       " 'meiganga, cm',\n",
       " 'cordoba, ar',\n",
       " 'shetpe, kz',\n",
       " 'dudinka, ru',\n",
       " 'abu kamal, sy',\n",
       " 'moa, cu',\n",
       " 'lircay, pe',\n",
       " 'itupiranga, br',\n",
       " 'mentok, id',\n",
       " 'karoi, zw',\n",
       " 'pocao de pedras, br',\n",
       " 'ulladulla, au',\n",
       " 'igra, ru',\n",
       " 'sumkino, ru',\n",
       " 'kawhia, nz',\n",
       " 'fevik, no',\n",
       " 'touros, br',\n",
       " 'toamasina, mg',\n",
       " 'batemans bay, au',\n",
       " 'de panne, be',\n",
       " 'bemidji, us',\n",
       " 'bilibino, ru',\n",
       " 'nazilli, tr',\n",
       " 'brokopondo, sr',\n",
       " 'henties bay, na',\n",
       " 'wau, pg',\n",
       " 'port hedland, au',\n",
       " 'praia, cv',\n",
       " 'poum, nc',\n",
       " 'novikovo, ru',\n",
       " 'palatka, ru',\n",
       " 'oleksandrivka, ua',\n",
       " 'yuzhno-yeniseyskiy, ru',\n",
       " 'lakes entrance, au',\n",
       " 'rungata, ki',\n",
       " 'butte, us',\n",
       " 'nantucket, us',\n",
       " 'pampierstad, za',\n",
       " 'witu, ke',\n",
       " 'flin flon, ca',\n",
       " 'patacamaya, bo',\n",
       " 'tlazazalca, mx',\n",
       " 'tres picos, mx',\n",
       " 'makat, kz',\n",
       " 'portland, au',\n",
       " 'augusta, us',\n",
       " 'kichmengskiy gorodok, ru',\n",
       " 'seguinon, ph',\n",
       " 'dondo, mz',\n",
       " 'menongue, ao',\n",
       " 'conselheiro pena, br',\n",
       " 'manta, ec',\n",
       " 'neverkino, ru',\n",
       " 'caruray, ph',\n",
       " 'pavlohrad, ua',\n",
       " 'zaplyusye, ru',\n",
       " 'vanimo, pg',\n",
       " 'shache, cn',\n",
       " 'chalmette, us',\n",
       " 'chimoio, mz',\n",
       " 'dutse, ng',\n",
       " 'sheridan, us',\n",
       " 'penhold, ca',\n",
       " 'ust-nera, ru',\n",
       " 'pueblo, us',\n",
       " 'skjervoy, no',\n",
       " 'grand-lahou, ci',\n",
       " 'dubbo, au',\n",
       " 'worland, us',\n",
       " 'kalisz, pl',\n",
       " 'poso, id',\n",
       " 'pingliang, cn',\n",
       " 'omsukchan, ru',\n",
       " 'mbandaka, cd',\n",
       " 'udachnyy, ru',\n",
       " 'aksu, cn',\n",
       " 'harboore, dk',\n",
       " 'ourem, pt',\n",
       " 'baherden, tm',\n",
       " 'sioni, ge',\n",
       " 'northam, au',\n",
       " 'sao bras de alportel, pt',\n",
       " 'laramie, us',\n",
       " 'sibolga, id',\n",
       " 'katangli, ru',\n",
       " 'makakilo city, us',\n",
       " 'tynda, ru',\n",
       " 'yurga, ru',\n",
       " 'bonthe, sl',\n",
       " 'sexsmith, ca',\n",
       " 'javanrud, ir',\n",
       " 'hearst, ca',\n",
       " ...]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of cities for which will will try to retrieve geocoordinates\n",
    "cities_input = cities_df[\"City-Country\"].tolist()\n",
    "\n",
    "# ****NOTE IN LINE BELOW THAT head() IN FRONT OF .tolist() AFFECTS SIZE OF LISTS BUT IS USEFUL FOR TEST PURPOSES****\n",
    "# cities_input = cities_df[\"City-Country\"].head(30).tolist()\n",
    "\n",
    "cities_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Google API Calls for City Geocoordinates\n",
    "* Gather geocoordinates for each city using a series of successive Google API calls.\n",
    "* Include a print log of each city not found.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City papara, pf not found\n",
      "City raga, sd not found\n",
      "City gat, ly not found\n",
      "City tim, ru not found\n",
      "City constitucion, mx not found\n",
      "City daru, pg not found\n",
      "City oktyabrskoye, ru not found\n",
      "City mikuni, jp not found\n",
      "City naze, jp not found\n",
      "City soe, id not found\n",
      "City komsomolskiy, ru not found\n",
      "City lata, sb not found\n",
      "City sur, om not found\n",
      "City labuhan, id not found\n",
      "City bereda, so not found\n",
      "City sola, vu not found\n",
      "City borba, pt not found\n",
      "City mutis, co not found\n",
      "City mercedes, uy not found\n",
      "City biltine, td not found\n",
      "City saint-georges, gf not found\n",
      "City muli, mv not found\n",
      "City lapua, fi not found\n",
      "City sale, au not found\n",
      "City pop, uz not found\n",
      "City santander, es not found\n",
      "City buchanan, lr not found\n",
      "City dinar, tr not found\n",
      "City tokur, ru not found\n",
      "City ngorongoro, tz not found\n",
      "City along, in not found\n",
      "City yamada, jp not found\n",
      "City twentynine palms, us not found\n",
      "City guider, cm not found\n",
      "City mahon, es not found\n",
      "City aras, no not found\n",
      "City warrington, us not found\n",
      "City asau, tv not found\n",
      "City lolua, tv not found\n",
      "City wajid, so not found\n",
      "City kalas, in not found\n",
      "City nara, ml not found\n",
      "City dauriya, ru not found\n",
      "City melfi, td not found\n",
      "City ati, td not found\n",
      "City degirmen, tr not found\n",
      "City mao, td not found\n",
      "City mana, gf not found\n",
      "City roma, au not found\n",
      "City fare, pf not found\n",
      "City dicabisagan, ph not found\n",
      "City moa, cu not found\n",
      "City patacamaya, bo not found\n",
      "City posse, br not found\n",
      "City bur gabo, so not found\n",
      "City paka, my not found\n",
      "City ler, sd not found\n",
      "City gorom-gorom, bf not found\n"
     ]
    }
   ],
   "source": [
    "# Set empty lists to hold characters height and mass\n",
    "target_cities = []\n",
    "target_lats = []\n",
    "target_lngs = []\n",
    "\n",
    "# Loop through each character\n",
    "for city1 in cities_input:\n",
    "    \n",
    "   # Try to extract latitude and longitude\n",
    "    try:\n",
    "        # Set url for API\n",
    "        target_url = f'https://maps.googleapis.com/maps/api/geocode/json?address={city1}&key={g_key}'\n",
    "        \n",
    "        # Run a request to endpoint and convert result to json\n",
    "        geo_data = requests.get(target_url).json()\n",
    "        \n",
    "        # Pause a few seconds to allow for processing delays\n",
    "        time.sleep(1) \n",
    "        \n",
    "        # Append returned latitude, longitude, and city\n",
    "        target_lats.append(geo_data[\"results\"][0][\"geometry\"][\"location\"][\"lat\"])\n",
    "        target_lngs.append(geo_data[\"results\"][0][\"geometry\"][\"location\"][\"lng\"])\n",
    "        target_cities.append(city1) # THE ORDER OF THIS APPEND IS CRITICAL!!!\n",
    "        \n",
    "        # Printed as Check\n",
    "        # print(f\"{city1} found! Appending longitude and latitude\")\n",
    "        \n",
    "    # Handle exceptions for cities whose geocoordiantes are not returned in the Google API\n",
    "    except:\n",
    "        # Append null values\n",
    "        print(f\"City {city1} not found\")\n",
    "        pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate number of cities for which lat-lng data successfully extracted\n",
    "# And verify lists to be merged into dataframe are of same length\n",
    "print(f\"Original Input Cities = {len(cities_input)}\")\n",
    "print(f\"Cities Not Found = {len(cities_input) - len(target_cities)}\")\n",
    "print()\n",
    "print(f\"Target Cities = {len(target_cities)}\")\n",
    "print(f\"Target Latitutdes = {len(target_lats)}\")\n",
    "print(f\"Target Longitudes = {len(target_lngs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate new dataframe with extracted with successfully extracted city-county, latitude and longitude data\n",
    "cities_dict = {\"City-Country\": target_cities, \"Actual Lats\": target_lats, \"Actual Lngs\": target_lngs}\n",
    "cities_df2 = pd.DataFrame(cities_dict)\n",
    "\n",
    "cities_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cities_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proof no duplicates were entered\n",
    "cities_dedupe_df = cities_df.drop_duplicates(subset=\"City-Country\")\n",
    "cities_dedupe_df2 = cities_df2.drop_duplicates(subset=\"City-Country\")\n",
    "\n",
    "print(f\"Number of records removed by deduplicaiton of Nearest City Search DF = {len(cities_df) - len(cities_dedupe_df)}\")\n",
    "print(f\"Number of records removed by deduplicaiton of City Geocoordinates DF = {len(cities_df2) - len(cities_dedupe_df2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform inner merge on the 2 dataframes\n",
    "df1 = cities_df\n",
    "df2 = cities_df2\n",
    "df = pd.merge(df1, df2, on=\"City-Country\")\n",
    "\n",
    "# Alternative syntax\n",
    "# df = df1.merge(df2, on=\"City-Country\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inner merge successful\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate distance using the trigonometric Haversine Formula\n",
    "![Trigonometry Explanation](../Images/trig_1.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list to capture distance calculations\n",
    "distance_list = []\n",
    "\n",
    "# radius of the Earth, 3,958.8 mi (6373.0 km)\n",
    "# presumably a blend of polar and equatorial radii\n",
    "R = 3958.8\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    \n",
    "    # coordinates - Used to search for Nearest City\n",
    "    lat1 = math.radians(row[\"Search Lats\"])\n",
    "    lon1 = math.radians(row[\"Search Lngs\"])\n",
    "    \n",
    "    # coordinates - Actual for City Selected\n",
    "    lat2 = math.radians(row[\"Actual Lats\"])\n",
    "    lon2 = math.radians(row[\"Search Lngs\"])\n",
    "    \n",
    "    # change in coordinates\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    \n",
    "    # Haversine formula\n",
    "    a = math.sin(dlat / 2)**2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon / 2)**2\n",
    "    \n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "    \n",
    "    distance = R * c\n",
    "    \n",
    "    distance_list.append(distance)\n",
    "\n",
    "# print(distance_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For convenience\n",
    "df[\"Distance (mi)\"] = distance_list\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Couunt the number of cities selected are in the combined data set\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of cities selected are within 60 miles\n",
    "len(df.loc[df[\"Distance (mi)\"] <= 60])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The original search for the nearest city involved 1,500 random geocoordinates.  This yielded just over 200 cities that were less than or equal to 60 miles from the original random geocoordinates.  As a result, we # expanded our random geocoordinates set by a factor of 2x or higher to increase the odds of selecting at least 500 target cities that were within the maximum 60 mile search radius. So, we reran the next time with 3,500 random geocoordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows that have Distance values greater than 60\n",
    "cities_60mi_df = df[~(df[\"Distance (mi)\"] > 60)]\n",
    "cities_60mi_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform OpenWeatherMap API calls for each city\n",
    "* Perform a weather check on each city using a series of successive API calls.\n",
    "* Include a print log of each city as it'sbeing processed (with the city number and city name).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save config information.\n",
    "url = \"http://api.openweathermap.org/data/2.5/weather?\"\n",
    "units = \"imperial\"\n",
    "\n",
    "# Build partial query URL\n",
    "query_url = f\"{url}appid={weather_api_key}&units={units}&q=\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_60mi_list = cities_60mi_df[\"City-Country\"].tolist()\n",
    "cities_60mi_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create list of cities within the 60 mi parameter from which to query the OpenWeather API\n",
    "cities_60mi_list = cities_60mi_df[\"City-Country\"].tolist()\n",
    "\n",
    "# set up lists to hold reponse info\n",
    "cities_60_found_list = []\n",
    "temp_max_list = []\n",
    "humid_list = []\n",
    "cloud_list = []\n",
    "wind_list = []\n",
    "time_list = []\n",
    "\n",
    "# Loop through the list of cities and perform a request for data on each\n",
    "for city_60mi in cities_60mi_list:\n",
    "    \n",
    "    # Try to extract maximum-temperature, humidity, cloudiness, and wind speed\n",
    "    try:\n",
    "        response = requests.get(query_url + city_60mi).json()\n",
    "        \n",
    "        # Pause a few seconds to allow for processing delays\n",
    "        time.sleep(1) \n",
    "        \n",
    "        temp_max_list.append(response[\"main\"][\"temp_max\"])\n",
    "        humid_list.append(response[\"main\"][\"humidity\"])\n",
    "        cloud_list.append(response[\"clouds\"][\"all\"])\n",
    "        wind_list.append(response[\"wind\"][\"speed\"])\n",
    "        timestamp_list.append(response[\"dt\"])\n",
    "        cities_60_found_list.append(city_60mi) \n",
    "        \n",
    "        # Printed as Check\n",
    "        print(f\"{city_60mi} found! Appending maximum temperature, humidity, cloudiness, and wind speed.\")\n",
    "\n",
    "    # Handle exceptions for cities whose geocoordiantes are not returned in the Google API\n",
    "    except:\n",
    "        # Append null values\n",
    "        print(f\"City {city_60mi} not found\")\n",
    "        pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate number of cities for which weather data successfully extracted\n",
    "# And verify lists to be merged into dataframe are of same length\n",
    "print(f\"Original Input Cities = {len(cities_60mi_list)}\")\n",
    "print(f\"Cities Not Found = {len(cities_60mi_list) - len(cities_60_found_list)}\")\n",
    "print()\n",
    "print(f\"Target Cities = {len(cities_60_found_list)}\")\n",
    "print(f\"Target Latitutdes = {len(temp_max_list)}\")\n",
    "print(f\"Target Longitudes = {len(humid_list)}\")\n",
    "print(f\"Target Longitudes = {len(cloud_list)}\")\n",
    "print(f\"Target Longitudes = {len(wind_list)}\")\n",
    "print(f\"Target Longitudes = {len(timestamp_list)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Raw Data to DataFrame\n",
    "* Export the city data into a .csv.\n",
    "* Display the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate new dataframe with extracted with successfully extracted weather data and city-country data\n",
    "city_weather_dict = {\"City-Country\": cities_60_found_list, \"Max Temp (F)\": temp_max_list, \"Humidity (%)\": humid_list, \\\n",
    "                     \"Cloud Cover (%)\": cloud_list, \"Wind Speed (mph)\": wind_list, \"Timestamp\": timestamp_list}\n",
    "city_weather_df = pd.DataFrame(city_weather_dict)\n",
    "\n",
    "city_weather_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add column converting timestamp to date\n",
    "city_weather_df[\"Date\"] = pd.to_datetime(city_weather_df[\"Timestamp\"], unit=\"s\")\n",
    "\n",
    "city_weather_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform inner merge on the 2 dataframes\n",
    "df01 = cities_60mi_df\n",
    "df02 = city_weather_df\n",
    "final_merge_df = pd.merge(df01, df02, on=\"City-Country\")\n",
    "\n",
    "# Alternative syntax\n",
    "# final_merge_df = df01.merge(df02, on=\"City-Country\")\n",
    "\n",
    "final_merge_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inner merge successful\n",
    "final_merge_dataset_size = len(final_merge_df)\n",
    "final_merge_dataset_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of conditions for determining assigning hemisphere\n",
    "hemisphere_conditions = [\n",
    "    (final_merge_df[\"Actual Lats\"] > 0),\n",
    "    (final_merge_df[\"Actual Lats\"] < 0),\n",
    "    (final_merge_df[\"Actual Lats\"] == 0)\n",
    "    ]\n",
    "\n",
    "# create a list of the values we want to assign for each condition\n",
    "hemishere_values = [\"Northern\", \"Southern\", \"Equator\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_merge_df[\"Hemisphere\"] = np.select(hemisphere_conditions, hemishere_values)\n",
    "final_merge_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hemisphere_df = pd.DataFrame(final_merge_df[\"Hemisphere\"].value_counts())\n",
    "hemisphere_df[\"Percent (%)\"] = hemisphere_df[\"Hemisphere\"] / final_merge_dataset_size *100\n",
    "hemisphere_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Northern Hemisphere has 68% of the Earth's land by area, while the Southern Hemisphere has 32%.  How close is our random distribution of cities to the disposition of landmass?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{round(hemisphere_df.iloc[0, 1], 1)}% of our randomly selected cities were in the Northern Hemisphere.\")\n",
    "print(f\"That's {round(abs(68 - hemisphere_df.iloc[0, 1]))}% points variance from the known percentage landmass in the Northern Hemisphere.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export dataframe with city name, country code, geocoordinates, search distance, and weather data to csv file\n",
    "* We have included the original search geocoordinates that selected nearest cities and the actual city geocoordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_merge_df.to_csv(output_data_file, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect the data and remove the cities where the humidity > 100%.\n",
    "----\n",
    "Skip this step if there are no cities that have humidity > 100%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect for any rows with humidity > 100%\n",
    "humid_over_100 = len(final_merge_df.loc[final_merge_df[\"Humidity (%)\"] > 100])\n",
    "print(f\"Number of cities reporting humiidty > 100% = {humid_over_100}\")\n",
    "print(f'''\n",
    "      100% is the maximum possible humidity measurement.\n",
    "      So measurement above 100% representes an error.\n",
    "      Any record that does so should be removed from the dataset.\n",
    "     ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out rows with humidity levels > 100% (or skip if not present)\n",
    "cw_filter_df1 = final_merge_df.loc[final_merge_df[\"Humidity (%)\"] <= 100]\n",
    "# cw_filter_df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cw_filter_df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Get the indices of cities that have humidity over 100%.\n",
    "index_over_100_humid = final_merge_df.index[final_merge_df[\"Humidity (%)\"] > 100].tolist()\n",
    "index_over_100_humid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALTERNATIVE METHOD TO TASK PERFORMED 2 CELLS ABOVE\n",
    "# Make a new DataFrame equal to the city data to drop all humidity outliers by index.\n",
    "# Passing \"inplace=False\" will make a copy of the city_data DataFrame, which we call \"clean_city_data\".\n",
    "\n",
    "cw_filter_df2 = final_merge_df.drop(index=index_over_100_humid)\n",
    "# cw_filter_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cw_filter_df2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the Data\n",
    "* Use proper labeling of the plots using plot titles (including date of analysis) and axes labels.\n",
    "* Save the plotted figures as .pngs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For convenience\n",
    "dfx = cw_filter_df1\n",
    "\n",
    "# Create separate dataframes for Northern and Southern Hemispheres\n",
    "dfn = dfx.loc[dfx[\"Hemisphere\"] == \"Northern\"]\n",
    "dfs = dfx.loc[dfx[\"Hemisphere\"] == \"Southern\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfn.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latitude vs. Temperature Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ax1 = dfx.plot.scatter(x='Actual Lats',\n",
    "                      y='Max Temp (F)',\n",
    "                      title=f\"City Latitude vs. Max Temperature ({date.today()})\\n\",\n",
    "                      grid=True, \n",
    "                      c='DarkBlue')\n",
    "\n",
    "# Set the x scale because otherwise it goes into weird negative numbers\n",
    "ax1.set_xlim((-80, 80))\n",
    "\n",
    "# Set the x-axis label\n",
    "ax1.set_xlabel(\"Latitude (degrees)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latitude vs. Humidity Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax2 = dfx.plot.scatter(x='Actual Lats',\n",
    "                      y='Humidity (%)',\n",
    "                      title=f\"City Latitude vs. Humidity ({date.today()})\\n\",\n",
    "                      grid=True, \n",
    "                      c='DarkBlue')\n",
    "\n",
    "# Set the x scale because otherwise it goes into weird negative numbers\n",
    "ax2.set_xlim((-80, 80))\n",
    "\n",
    "# Set the x-axis label\n",
    "ax2.set_xlabel(\"Latitude (degrees)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latitude vs. Cloudiness Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax3 = dfx.plot.scatter(x='Actual Lats',\n",
    "                      y='Cloud Cover (%)',\n",
    "                      title=f\"City Latitude vs. Cloudiness ({date.today()})\\n\",\n",
    "                      grid=True, \n",
    "                      c='DarkBlue')\n",
    "\n",
    "# Set the x scale because otherwise it goes into weird negative numbers\n",
    "ax3.set_xlim((-80, 80))\n",
    "\n",
    "# Set the x-axis label\n",
    "ax3.set_xlabel(\"Latitude (degrees)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latitude vs. Wind Speed Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax4 = dfx.plot.scatter(x='Actual Lats',\n",
    "                      y='Wind Speed (mph)',\n",
    "                      title=f\"City Latitude vs. Wind Speed ({date.today()})\\n\",\n",
    "                      grid=True, \n",
    "                      c='DarkBlue')\n",
    "\n",
    "# Set the x scale because otherwise it goes into weird negative numbers\n",
    "ax4.set_xlim((-80, 80))\n",
    "\n",
    "# Set the x-axis label\n",
    "ax4.set_xlabel(\"Latitude (degrees)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression formula explanation\n",
    "![Trigonometry Explanation](../Images/slopegraphlabel2.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Calculate Regression Line Coordinates - Northern Hemisphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Northern Hemisphere - Max Temperature vs. Latitude Linear Regression\n",
    "# The polyfit function from numpy performs a least squares polynomial fit over the data that it is given. \n",
    "# We want a linear regression over the data in columns Yr and Tmax so we pass these as parameters. \n",
    "# The final parameter is the degree of the polynomial. For linear regression the degree is 1.\n",
    "# Calculate y-axis coordinates and insert as column TLregr (North Hemisphere Temperature v Latitutde regression line)\n",
    "\n",
    "d = np.polyfit(dfn['Actual Lats'],dfn['Max Temp (F)'],1)\n",
    "f = np.poly1d(d)\n",
    "dfn.insert(15,'TLregr',f(dfn['Actual Lats']))\n",
    "\n",
    "# Calculate regression formula\n",
    "TLn_m = d[0]\n",
    "TLn_b = d[1]\n",
    "TLn_rl = f\"y = {round(TLn_m, 1)}x + {round(TLn_b, 1)}\"\n",
    "print(TLn_rl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Northern Hemisphere - Humidity vs. Latitude Linear Regression\n",
    "# The polyfit function from numpy performs a least squares polynomial fit over the data that it is given. \n",
    "# We want a linear regression over the data in columns Yr and Tmax so we pass these as parameters. \n",
    "# The final parameter is the degree of the polynomial. For linear regression the degree is 1.\n",
    "# Calculate y-axis coordinates and insert as column TLregr (North Hemisphere Temperature v Latitutde regression line)\n",
    "\n",
    "d = np.polyfit(dfn['Actual Lats'],dfn['Humidity (%)'],1)\n",
    "f = np.poly1d(d)\n",
    "dfn.insert(16,'HLregr',f(dfn['Actual Lats']))\n",
    "\n",
    "# Calculate regression formula\n",
    "HLn_m = d[0]\n",
    "HLn_b = d[1]\n",
    "HLn_rl = f\"y = {round(HLn_m, 1)}x + {round(HLn_b, 1)}\"\n",
    "print(HLn_rl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Northern Hemisphere - Cloudiness vs. Latitude Linear Regression\n",
    "# The polyfit function from numpy performs a least squares polynomial fit over the data that it is given. \n",
    "# We want a linear regression over the data in columns Yr and Tmax so we pass these as parameters. \n",
    "# The final parameter is the degree of the polynomial. For linear regression the degree is 1.\n",
    "# Calculate y-axis coordinates and insert as column TLregr (North Hemisphere Temperature v Latitutde regression line)\n",
    "\n",
    "d = np.polyfit(dfn['Actual Lats'],dfn['Cloud Cover (%)'],1)\n",
    "f = np.poly1d(d)\n",
    "dfn.insert(17,'CLregr',f(dfn['Actual Lats']))\n",
    "\n",
    "# Calculate regression formula\n",
    "CLn_m = d[0]\n",
    "CLn_b = d[1]\n",
    "CLn_rl = f\"y = {round(CLn_m, 1)}x + {round(CLn_b, 1)}\"\n",
    "print(CLn_rl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Northern Hemisphere - Wind Speed vs. Latitude Linear Regression\n",
    "# The polyfit function from numpy performs a least squares polynomial fit over the data that it is given. \n",
    "# We want a linear regression over the data in columns Yr and Tmax so we pass these as parameters. \n",
    "# The final parameter is the degree of the polynomial. For linear regression the degree is 1.\n",
    "# Calculate y-axis coordinates and insert as column TLregr (North Hemisphere Temperature v Latitutde regression line)\n",
    "\n",
    "d = np.polyfit(dfn['Actual Lats'],dfn['Wind Speed (mph)'],1)\n",
    "f = np.poly1d(d)\n",
    "dfn.insert(18,'WLregr',f(dfn['Actual Lats']))\n",
    "\n",
    "# Calculate regression formula\n",
    "WLn_m = d[0]\n",
    "WLn_b = d[1]\n",
    "WLn_rl = f\"y = {round(WLn_m, 1)}x + {round(WLn_b, 1)}\"\n",
    "print(WLn_rl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfn.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Calculate Regression Line Coordinates - Southern Hemisphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Southern Hemisphere - Max Temperature vs. Latitude Linear Regression\n",
    "# The polyfit function from numpy performs a least squares polynomial fit over the data that it is given. \n",
    "# We want a linear regression over the data in columns Yr and Tmax so we pass these as parameters. \n",
    "# The final parameter is the degree of the polynomial. For linear regression the degree is 1.\n",
    "# Calculate y-axis coordinates and insert as column TLregr (North Hemisphere Temperature v Latitutde regression line)\n",
    "\n",
    "d = np.polyfit(dfs['Actual Lats'],dfs['Max Temp (F)'],1)\n",
    "f = np.poly1d(d)\n",
    "dfs.insert(15,'TLregr',f(dfs['Actual Lats']))\n",
    "\n",
    "# Calculate regression formula\n",
    "TLs_m = d[0]\n",
    "TLs_b = d[1]\n",
    "TLs_rl = f\"y = {round(TLs_m, 1)}x + {round(TLs_b, 1)}\"\n",
    "print(TLs_rl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Southern Hemisphere - Humidity vs. Latitude Linear Regression\n",
    "# The polyfit function from numpy performs a least squares polynomial fit over the data that it is given. \n",
    "# We want a linear regression over the data in columns Yr and Tmax so we pass these as parameters. \n",
    "# The final parameter is the degree of the polynomial. For linear regression the degree is 1.\n",
    "# Calculate y-axis coordinates and insert as column TLregr (North Hemisphere Temperature v Latitutde regression line)\n",
    "\n",
    "d = np.polyfit(dfs['Actual Lats'],dfs['Humidity (%)'],1)\n",
    "f = np.poly1d(d)\n",
    "dfs.insert(16,'HLregr',f(dfs['Actual Lats']))\n",
    "\n",
    "# Calculate regression formula\n",
    "HLs_m = d[0]\n",
    "HLs_b = d[1]\n",
    "HLs_rl = f\"y = {round(HLs_m, 1)}x + {round(HLs_b, 1)}\"\n",
    "print(HLs_rl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Southern Hemisphere - Cloudiness vs. Latitude Linear Regression\n",
    "# The polyfit function from numpy performs a least squares polynomial fit over the data that it is given. \n",
    "# We want a linear regression over the data in columns Yr and Tmax so we pass these as parameters. \n",
    "# The final parameter is the degree of the polynomial. For linear regression the degree is 1.\n",
    "# Calculate y-axis coordinates and insert as column TLregr (North Hemisphere Temperature v Latitutde regression line)\n",
    "\n",
    "d = np.polyfit(dfs['Actual Lats'],dfs['Cloud Cover (%)'],1)\n",
    "f = np.poly1d(d)\n",
    "dfs.insert(17,'CLregr',f(dfs['Actual Lats']))\n",
    "\n",
    "# Calculate regression formula\n",
    "CLs_m = d[0]\n",
    "CLs_b = d[1]\n",
    "CLs_rl = f\"y = {round(CLs_m, 1)}x + {round(CLs_b, 1)}\"\n",
    "print(CLs_rl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Southern Hemisphere - Wind Speed vs. Latitude Linear Regression\n",
    "# The polyfit function from numpy performs a least squares polynomial fit over the data that it is given. \n",
    "# We want a linear regression over the data in columns Yr and Tmax so we pass these as parameters. \n",
    "# The final parameter is the degree of the polynomial. For linear regression the degree is 1.\n",
    "# Calculate y-axis coordinates and insert as column TLregr (North Hemisphere Temperature v Latitutde regression line)\n",
    "\n",
    "d = np.polyfit(dfs['Actual Lats'],dfs['Wind Speed (mph)'],1)\n",
    "f = np.poly1d(d)\n",
    "dfs.insert(18,'WLregr',f(dfs['Actual Lats']))\n",
    "\n",
    "# Calculate regression formula\n",
    "WLs_m = d[0]\n",
    "WLs_b = d[1]\n",
    "WLs_rl = f\"y = {round(WLs_m, 1)}x + {round(WLs_b, 1)}\"\n",
    "print(WLs_rl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Northern Hemisphere - Max Temp vs. Latitude Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = f\"legend={TLn_rl}\"\n",
    "\n",
    "# Plot scatter\n",
    "ax = dfn.plot.scatter(x='Actual Lats',\n",
    "                      y='Max Temp (F)',\n",
    "                      title=f\"City Latitude vs. Max Temperature ({date.today()})\\n Northern Hemisphere\",\n",
    "                      c='DarkBlue')\n",
    "\n",
    "# Plot regression line, with a grid, omitting legend (important)\n",
    "dfn.plot(x='Actual Lats', y='TLregr', color='Red', legend=False, grid=True, ax=ax)\n",
    "\n",
    "# Set the x-axis label and regression line formula as annotation\n",
    "ax.set_xlabel(\"Latitude (degrees)\")\n",
    "ax.annotate(f'{TLn_rl}', xy= (0, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Southern Hemisphere - Max Temp vs. Latitude Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot scatter\n",
    "ax = dfs.plot.scatter(x='Actual Lats',\n",
    "                      y='Max Temp (F)',\n",
    "                      title=f\"City Latitude vs. Max Temperature ({date.today()})\\n Southern Hemisphere\",\n",
    "                      c='DarkBlue')\n",
    "\n",
    "# Plot regression line, with a grid, omitting legend (important)\n",
    "dfs.plot(x='Actual Lats', y='TLregr', color='Red', legend=False, grid=True, ax=ax)\n",
    "\n",
    "# Set the x-axis label and regression line formula as annotation\n",
    "ax.set_xlabel(\"Latitude (degrees)\")\n",
    "ax.annotate(f'{TLs_rl}', xy= (-50, 80))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Northern Hemisphere - Humidity (%) vs. Latitude Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot scatter\n",
    "ax = dfn.plot.scatter(x='Actual Lats',\n",
    "                      y='Humidity (%)',\n",
    "                      title=f\"City Latitude vs. Humidity ({date.today()})\\n Northern Hemisphere\",\n",
    "                      c='DarkBlue')\n",
    "\n",
    "# Plot regression line, with a grid, omitting legend (important)\n",
    "dfn.plot(x='Actual Lats', y='HLregr', color='Red', legend=False, grid=True, ax=ax)\n",
    "\n",
    "# Set the x-axis label and regression line formula as annotation\n",
    "ax.set_xlabel(\"Latitude (degrees)\")\n",
    "ax.annotate(f'{HLn_rl}', xy= (50, 30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Southern Hemisphere - Humidity (%) vs. Latitude Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot scatter\n",
    "ax = dfs.plot.scatter(x='Actual Lats',\n",
    "                      y='Humidity (%)',\n",
    "                      title=f\"City Latitude vs. Humidity ({date.today()})\\n Southern Hemisphere\",\n",
    "                      c='DarkBlue')\n",
    "\n",
    "# Plot regression line, with a grid, omitting legend (important)\n",
    "dfs.plot(x='Actual Lats', y='HLregr', color='Red', legend=False, grid=True, ax=ax)\n",
    "\n",
    "# Set the x-axis label and regression line formula as annotation\n",
    "ax.set_xlabel(\"Latitude (degrees)\")\n",
    "ax.annotate(f'{HLs_rl}', xy= (-45, 40))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Northern Hemisphere - Cloudiness (%) vs. Latitude Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot scatter\n",
    "ax = dfn.plot.scatter(x='Actual Lats',\n",
    "                      y='Cloud Cover (%)',\n",
    "                      title=f\"City Latitude vs. Cloudiness ({date.today()})\\n Northern Hemisphere\",\n",
    "                      c='DarkBlue')\n",
    "\n",
    "# Plot regression line, with a grid, omitting legend (important)\n",
    "dfn.plot(x='Actual Lats', y='CLregr', color='Red', legend=False, grid=True, ax=ax)\n",
    "\n",
    "# Set the x-axis label and regression line formula as annotation\n",
    "ax.set_xlabel(\"Latitude (degrees)\")\n",
    "ax.annotate(f'{CLn_rl}', xy= (25, 25))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Southern Hemisphere - Cloudiness (%) vs. Latitude Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot scatter\n",
    "ax = dfs.plot.scatter(x='Actual Lats',\n",
    "                      y='Cloud Cover (%)',\n",
    "                      title=f\"City Latitude vs. Cloudiness ({date.today()})\\n Southern Hemisphere\",\n",
    "                      c='DarkBlue')\n",
    "\n",
    "# Plot regression line, with a grid, omitting legend (important)\n",
    "dfs.plot(x='Actual Lats', y='CLregr', color='Red', legend=False, grid=True, ax=ax)\n",
    "\n",
    "# Set the x-axis label and regression line formula as annotation\n",
    "ax.set_xlabel(\"Latitude (degrees)\")\n",
    "ax.annotate(f'{CLs_rl}', xy= (-45, 50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Northern Hemisphere - Wind Speed (mph) vs. Latitude Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot scatter\n",
    "ax = dfn.plot.scatter(x='Actual Lats',\n",
    "                      y='Wind Speed (mph)',\n",
    "                      title=f\"City Latitude vs. Wind Speed ({date.today()})\\n Northern Hemisphere\",\n",
    "                      c='DarkBlue')\n",
    "\n",
    "# Plot regression line, with a grid, omitting legend (important)\n",
    "dfn.plot(x='Actual Lats', y='WLregr', color='Red', legend=False, grid=True, ax=ax)\n",
    "\n",
    "# Set the x-axis label and regression line formula as annotation\n",
    "ax.set_xlabel(\"Latitude (degrees)\")\n",
    "ax.annotate(f'{WLn_rl}', xy= (5, 27))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Southern Hemisphere - Wind Speed (mph) vs. Latitude Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot scatter\n",
    "ax = dfs.plot.scatter(x='Actual Lats',\n",
    "                      y='Wind Speed (mph)',\n",
    "                      title=f\"City Latitude vs. Wind Speed ({date.today()})\\n Southern Hemisphere\",\n",
    "                      c='DarkBlue')\n",
    "\n",
    "# Plot regression line, with a grid, omitting legend (important)\n",
    "dfs.plot(x='Actual Lats', y='WLregr', color='Red', legend=False, grid=True, ax=ax)\n",
    "\n",
    "# Set the x-axis label and regression line formula as annotation\n",
    "ax.set_xlabel(\"Latitude (degrees)\")\n",
    "ax.annotate(f'{CLn_rl}', xy= (-45, 12.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nteract": {
   "version": "0.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
